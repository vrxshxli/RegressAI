<div align="center">
  
# ğŸ“‰ **RegressAI**

<img width="1024" height="318" alt="image" src="https://github.com/user-attachments/assets/e2a0c13d-72a6-499f-9955-8fd53f8fcff6" />

### *Version Control & Regression Testing for LLM APIs*

> **Stop breaking your prompts. Ship AI features with confidence.**
> **Automated Judging â€¢ Hybrid Analysis â€¢ Auto-Fixing â€¢ CI/CD Ready**

</div>

---

## ğŸ›¡ï¸ **The Safety Net for GenAI Engineering**

**RegressAI** is a unified platform that prevents "prompt drift" and regression. It compares your new prompt versions against historical baselines to detect degradation in quality, safety, and structure.

Powered by a **Hybrid Evaluation Engine** (LLM Semantic + Deterministic Logic), it doesn't just find bugsâ€”it suggests how to fix them using **Google Gemini**.

---

## ğŸš€ **Core Superpowers**

| Feature | The Magic Behind It |
| --- | --- |
| ğŸ§  **Unified Analyzer** | Uses **Groq (Llama-3-70b)** with forced JSON mode to guarantee valid, structured verdicts |
| ğŸ•µï¸ **Root Cause Detection** | Classifies regressions into specific categories: `SAFETY`, `HALLUCINATION`, `STRUCTURE`, or `CONFIDENCE` |
| ğŸ›¡ï¸ **Deterministic Fallback** | If the LLM Judge fails, a heuristic engine takes over to analyze structure, tone, and safety flags |
| ğŸ”§ **Auto-Fixer Agent** | A "Layer-3" agent (Gemini) proposes architecture-aware prompt improvements based on the detected regression |
| ğŸ’¸ **Usage & Billing** | Integrated **Razorpay** support for premium tier management |

---

## ğŸ—ï¸ **Architecture: Hybrid & Robust**

```mermaid
graph LR
    A[Frontend<br/>React + Vite] -->|1. Submit Prompt A/B| B(FastAPI Backend)
    B -->|2. Fetch History| DB[(MongoDB)]
    B -->|3. Evaluate| C{Unified Analyzer}
    C -->|Strategy A| D[Groq Llama-3<br/>Semantic Analysis]
    C -->|Strategy B| E[Deterministic<br/>Heuristic Engine]
    D --> F[Verdict: Regression/Improved]
    E --> F
    F -->|If Regression| G[Gemini Fixer]
    G -->|Suggested Fix| A

```
<img width="1324" height="655" alt="image" src="https://github.com/user-attachments/assets/fcab181a-5be8-4dcf-bff6-f8d164bb3f71" />
<img width="1144" height="621" alt="image" src="https://github.com/user-attachments/assets/d89ebb12-ae5a-49ad-85af-ff56e200a67d" />

---

## ğŸ”¬ **Technical Brilliance**

### **1. The "Indestructible" JSON Judge**

We force Llama-3 to output valid JSON using `response_format={"type": "json_object"}` and sophisticated retry logic with varying temperatures.

```python
# From backend/app/unified_analyzer.py
def _call_groq_json_mode(api_key, prompt, temperature=0.3):
    response = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[...],
        response_format={"type": "json_object"}  # ğŸ”¥ FORCES JSON OUTPUT
    )
    # Guaranteed dictionary return
    return json.loads(response.choices[0].message.content)

```

### **2. Intelligent Heuristic Fallback**

When semantic analysis is unavailable, the system falls back to strict rule-based logic to ensure safety never drops.

```python
# From backend/app/prompt_fixer.py
def _heuristic_fallback(issues, ...):
    if "HALLUCINATION" in root_causes:
        suggestions.append({
            "scope": "rag",
            "change_type": "grounding",
            "suggested_text": "Introduce retrieval grounding..."
        })
    # Returns a valid schema even without LLM
    return structured_response

```

---

## âš™ï¸ **Setup in 3 Minutes**

### **Prerequisites**

* Python 3.10+
* Node.js 18+
* MongoDB (Local or Atlas)
* API Keys: `GROQ_API_KEY`, `GEMINI_API_KEY`

### **Step 1: Backend (FastAPI)**

```bash
cd backend
pip install -r requirements.txt
# Start the API server
uvicorn app.main:app --reload --port 8000

```

### **Step 2: Frontend (Vite)**

```bash
cd Frontend
npm install
# Start the UI
npm run dev

```

The app will live at **http://localhost:5173** and communicate with the backend at **http://localhost:8000**.

---

## ğŸ“¸ **See It in Action**

<div align="center">

### **Unified Analysis Dashboard**

*(Visualize your regression tests, confidence scores, and root causes)*
<img alt="Dashboard" src="[https://via.placeholder.com/800x400?text=Analysis+Dashboard+Preview](https://www.google.com/search?q=https://via.placeholder.com/800x400%3Ftext%3DAnalysis%2BDashboard%2BPreview)" />

</div>

---

## ğŸ› ï¸ **Project Structure**

```
RegressAI/
â”œâ”€â”€ Frontend/                 # React + Vite Application
â”‚   â”œâ”€â”€ src/components/       # Visualizations, Modals, Panels
â”‚   â”œâ”€â”€ src/services/         # API & Auth connections
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ backend/                  # FastAPI Application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ analysis/         # Behavioral & Tradeoff engines
â”‚   â”‚   â”œâ”€â”€ api/              # Routes (Analyze, Razorpay, Mock)
â”‚   â”‚   â”œâ”€â”€ unified_analyzer.py # ğŸš€ Core Llama-3 Logic
â”‚   â”‚   â”œâ”€â”€ prompt_fixer.py   # ğŸ”§ Gemini Repair Logic
â”‚   â”‚   â””â”€â”€ main.py           # Entry point
â”‚   â””â”€â”€ requirements.txt

```

---

## ğŸŒ± **Contributing**

We welcome pull requests! Please check the `backend/app/schemas.py` for data models before submitting API changes.

```bash
git clone https://github.com/Sparky17561/RegressAI.git
git checkout -b feature/amazing-feature
# ... code ...
git push origin feature/amazing-feature

```

---

## ğŸ“„ **License**

[MIT License](https://www.google.com/search?q=LICENSE) â€” Open source and ready for production.

---

<div align="center">

### **RegressAI**

**Because "it works on my machine" isn't good enough for LLMs.**

</div>
